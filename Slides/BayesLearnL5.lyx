#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass beamer
\begin_preamble
\setcounter{MaxMatrixCols}{10}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathpazo}
\usepackage{hyperref}
\usepackage{multimedia}
\usepackage{xcolor}
\usepackage{colortbl}
\definecolor{RawSienna}{cmyk}{0,0.87,0.82,0.31}
\definecolor{gray97}{cmyk}{0,0,0,0.03}
\definecolor{robinsegg}{cmyk}{0.18,0.04,0,0.07}
\definecolor{cola}{cmyk}{0,0.315,0.35,0.155}

\newenvironment{stepenumerate}{\begin{enumerate}[<+->]}{\end{enumerate}}
\newenvironment{stepitemize}{\begin{itemize}[<+->]}{\end{itemize} }
\newenvironment{stepenumeratewithalert}{\begin{enumerate}[<+-| alert@+>]}{\end{enumerate}}
\newenvironment{stepitemizewithalert}{\begin{itemize}[<+-| alert@+>]}{\end{itemize} }
\usecolortheme[named=RawSienna]{structure}
%\usecolortheme[RGB={205,0,0}]{structure}
\setbeamertemplate{navigation symbols}{}
\useoutertheme{infolines}
\usetheme{default}
\setbeamertemplate{blocks}[shadow=true]
%\setbeamerfont{structure}{shape=\itshape}
\usefonttheme{structuresmallcapsserif}
\setbeamertemplate{background canvas}{
 % \ifnum \thepage>0 \relax % we are on the first page
%\includegraphics[width=\paperwidth,height=\paperheight]{/home/mv/Dropbox/Foton/IconsWallpaper/greyribbonLighter.jpg}
 % \else
 	% No background for page 2 and onwards
 % \fi
}
\end_preamble
\options xcolor=svgnames, handout
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "palatino" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Bayesian Learning
\end_layout

\end_inset

Bayesian Learning - Lecture 5 
\end_layout

\begin_layout Author
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Mattias Villani
\end_layout

\end_inset

Mattias Villani
\end_layout

\begin_layout Institute

\series bold
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\series bold
Statistics, LiU
\end_layout

\end_inset

Division of Statistics and Machine Learning
\begin_inset Newline newline
\end_inset

Department of Computer and Information Science
\begin_inset Newline newline
\end_inset

LinkÃ¶ping University 
\end_layout

\begin_layout Date
\begin_inset space \thinspace{}
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Lecture overview
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Normal model with conjugate prior
\end_layout

\begin_layout Itemize
The linear regression model
\end_layout

\begin_layout Itemize
Non-linear regression
\end_layout

\begin_layout Itemize
Regularization priors
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal model - normal prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Model
\begin_inset Formula 
\[
y_{1},...,y_{n}|\theta,\sigma^{2}\overset{iid}{\sim}N(\theta,\sigma^{2})
\]

\end_inset


\end_layout

\begin_layout Itemize
Conjugate prior
\begin_inset Formula 
\begin{gather*}
\theta|\sigma^{2}\sim N\left(\mu_{0},\frac{\sigma^{2}}{\kappa_{0}}\right)\\
\sigma^{2}\sim Inv\text{-}\chi^{2}(\nu_{0},\sigma_{0}^{2})
\end{gather*}

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Normal model with normal prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Posterior 
\begin_inset Formula 
\begin{gather*}
\theta|y,\sigma^{2}\sim N\left(\mu_{n},\frac{\sigma^{2}}{\kappa_{n}}\right)\\
\sigma^{2}|y\sim Inv\text{-}\chi^{2}(\nu_{n},\sigma_{n}^{2}).
\end{gather*}

\end_inset

where
\begin_inset Formula 
\begin{eqnarray*}
\mu_{n} & = & \frac{\kappa_{0}}{\kappa_{0}+n}\mu_{0}+\frac{n}{\kappa_{0}+n}\bar{y}\\
\kappa_{n} & = & \kappa_{0}+n\\
\nu_{n} & = & \nu_{0}+n\\
\nu_{n}\sigma_{n}^{2} & = & \nu_{0}\sigma_{0}^{2}+(n-1)s^{2}+\frac{\kappa_{0}n}{\kappa_{0}+n}(\bar{y}-\mu_{0})^{2}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Pause

\end_layout

\begin_layout Itemize
Marginal posterior
\begin_inset Formula 
\begin{gather*}
\theta\sim t_{\nu_{n}}\left(\mu_{n},\sigma_{n}^{2}/\kappa_{n}\right)
\end{gather*}

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
The Linear Regression Model 
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The ordinary linear regression model:
\begin_inset Formula 
\begin{eqnarray*}
y_{i} & = & \beta_{1}x_{i1}+\beta_{2}x_{i2}+...+\beta_{k}x_{ik}+\varepsilon_{i}\\
 &  & \varepsilon_{i}\overset{iid}{\sim}N(0,\sigma^{2}).
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Parameters 
\begin_inset Formula $\theta=(\beta_{1},\beta_{2},...,\beta_{k},\sigma^{2})$
\end_inset

.
\end_layout

\begin_layout Itemize
Assumptions:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $E(y_{i})=\beta_{1}x_{i1}+\beta_{2}x_{i2}+...+\beta_{k}x_{ik}$
\end_inset

 (linear function)
\end_layout

\begin_layout Itemize
\begin_inset Formula $Var(y_{i})=\sigma^{2}$
\end_inset

 (homoscedasticity)
\end_layout

\begin_layout Itemize
\begin_inset Formula $Corr(y_{i},y_{j}|X,\beta,\sigma^{2})=0$
\end_inset

, 
\begin_inset Formula $i\neq j$
\end_inset

.
\end_layout

\begin_layout Itemize
Normality of 
\begin_inset Formula $\varepsilon_{i}$
\end_inset

.
\end_layout

\begin_layout Itemize
The x's are assumed known (non-random).
\end_layout

\end_deeper
\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear regression in matrix form
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The linear regression model in matrix form
\begin_inset Formula 
\[
\underset{(n\times1)}{\mathbf{y}}=\underset{(n\times k)(k\times1)}{\mathbf{X}\beta}+\underset{(n\times1)}{\varepsilon}
\]

\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\mathbf{y} & = & \left(\begin{array}{c}
y_{1}\\
\vdots\\
y_{n}
\end{array}\right),\text{ }\beta=\left(\begin{array}{c}
\beta_{1}\\
\vdots\\
\beta_{k}
\end{array}\right),\text{ }\varepsilon=\left(\begin{array}{c}
\varepsilon_{1}\\
\vdots\\
\varepsilon_{n}
\end{array}\right)\\
\mathbf{X} & = & \left(\begin{array}{c}
\mathbf{x}_{1}^{\prime}\\
\vdots\\
\mathbf{x}_{n}^{\prime}
\end{array}\right)=\left(\begin{array}{ccc}
x_{11} & \cdots & x_{1k}\\
\vdots & \ddots & \vdots\\
x_{n1} & \cdots & x_{nk}
\end{array}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Usually 
\begin_inset Formula $x_{i1}=1$
\end_inset

, for all 
\begin_inset Formula $i$
\end_inset

.
 
\begin_inset Formula $\beta_{1}$
\end_inset

 is the intercept.
\end_layout

\begin_layout Itemize
Likelihood for the full sample
\begin_inset Formula 
\[
\mathbf{y}|\beta,\sigma^{2},\mathbf{X}\sim N(\mathbf{X}\beta,\sigma^{2}I_{n})
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear regression - uniform prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Standard non-informative prior: uniform on (
\begin_inset Formula $\beta,\log\sigma^{2}$
\end_inset

)
\begin_inset Formula 
\[
p(\beta,\sigma^{2})\propto\sigma^{-2}
\]

\end_inset


\end_layout

\begin_layout Itemize
Joint posterior of 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

:
\begin_inset Formula 
\begin{eqnarray*}
\beta|\sigma^{2},\mathbf{y} & \sim & N\left[\hat{\beta},\sigma^{2}(\mathbf{X}^{\prime}\mathbf{X})^{-1}\right]\\
\sigma^{2}|\mathbf{y} & \sim & Inv\text{-}\chi^{2}(n-k,s^{2})
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\hat{\beta}=(\mathbf{X}^{\prime}\mathbf{X})^{-1}\mathbf{X}^{\prime}\mathbf{y}$
\end_inset

 and 
\begin_inset Formula $s^{2}=\frac{1}{n-k}(\mathbf{y}-\mathbf{X}\hat{\beta})^{\prime}(\mathbf{y}-\mathbf{X}\hat{\beta}).$
\end_inset


\end_layout

\begin_layout Itemize
Simulate from the joint posterior by iteratively simulating from
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $p(\sigma^{2}|\mathbf{y})$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $p(\beta|\sigma^{2},\mathbf{y})$
\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Marginal posterior of 
\begin_inset Formula $\beta:$
\end_inset


\begin_inset Formula 
\[
\beta|\mathbf{y}\sim t_{n-k}\left[\hat{\beta},s^{2}(X^{\prime}X)^{-1}\right]
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Linear regression - conjugate prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Joint prior for 
\begin_inset Formula $\beta$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2} & \sim N\left(\mu_{0},\sigma^{2}\Omega_{0}^{-1}\right)\\
\sigma^{2} & \sim Inv-\chi^{2}\left(\nu_{0},\sigma_{0}^{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
Posterior
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2},\mathbf{y} & \sim N\left[\mu_{n},\sigma^{2}\Omega_{n}^{-1}\right]\\
\sigma^{2}\vert\mathbf{y} & \sim Inv-\chi^{2}\left(\nu_{n},\sigma_{n}^{2}\right)
\end{align*}

\end_inset

 
\begin_inset Formula 
\begin{align*}
\mu_{n} & =\left(\mathbf{X}'\mathbf{X}+\Omega_{0}\right)^{-1}\left(\mathbf{X}'\mathbf{X}\hat{\beta}+\Omega_{0}\mu_{0}\right)\\
\Omega_{n} & =\mathbf{X}'\mathbf{X}+\Omega_{0}\\
\nu_{n} & =\nu_{0}+n\\
\nu_{n}\sigma_{n}^{2} & =\nu_{0}\sigma_{0}^{2}+\left(\mathbf{y}'\mathbf{y}+\mu_{0}'\Omega_{0}\mu_{0}-\mu_{n}'\Omega_{n}\mu_{n}\right)
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Polynomial regression
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Polynomial regression
\series default
\color inherit

\begin_inset Formula 
\[
f(x_{i})=\beta_{0}+\beta_{1}x_{i}+\beta_{2}x_{i}^{2}+...+\beta_{k}x_{i}^{k}.
\]

\end_inset


\begin_inset Formula 
\[
\mathbf{y}=\mathbf{X}_{P}\beta+\varepsilon,
\]

\end_inset

where 
\begin_inset Formula 
\[
\mathbf{X}_{P}=(1,x,x^{2},...,x^{k}).
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename quadraticBasis.eps
	scale 35

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Spline regression
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Polynomials are too global.
 Need more local basis functions.
\end_layout

\begin_layout Itemize

\series bold
\shape italic
\emph on
\color blue
Truncated power splines 
\color black
given 
\color blue
knot
\color black
 locations 
\begin_inset Formula $k_{1},...,k_{m}$
\end_inset


\color blue
 
\series default
\shape default
\emph default
\color inherit

\begin_inset Formula 
\[
b_{ij}=\left\{ \begin{array}{c}
(x_{i}-k_{j})^{p}\text{ \ \ if }x_{i}>k_{j}\\
0\text{ otherwise}
\end{array}\right.
\]

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename brokenStickBasis.eps
	scale 40

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Splines, cont.
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Note: given the knots, the non-parametric spline regression model is a linear
 regression of 
\begin_inset Formula $y$
\end_inset

 on the 
\begin_inset Formula $m$
\end_inset

 'dummy variables' 
\begin_inset Formula $b_{j}$
\end_inset


\begin_inset Formula 
\[
\mathbf{y}=\mathbf{X}_{b}\beta+\varepsilon,
\]

\end_inset

where 
\begin_inset Formula $X_{b}$
\end_inset

 is the basis regression matrix 
\begin_inset Formula 
\[
\mathbf{X}_{b}=(b_{1},...,b_{m}).
\]

\end_inset


\end_layout

\begin_layout Itemize
It is also common to include an intercept and the linear part of the model
 separately.
 In this case we have
\begin_inset Formula 
\[
\mathbf{X}_{b}=(1,x,b_{1},...,b_{m}).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Smoothness prior for splines
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Problem: too many knots leads to 
\series bold
over-fitting
\series default
.
 
\end_layout

\begin_layout Itemize
Solution: 
\series bold
smoothness/shrinkage/regularization prior
\series default

\begin_inset Formula 
\[
\beta_{i}|\sigma^{2}\overset{iid}{\sim}N\left(0,\frac{\sigma^{2}}{\lambda}\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
Larger 
\begin_inset Formula $\lambda$
\end_inset

 gives smoother fit.
 Note: here we have 
\begin_inset Formula $\mbox{\Omega}_{0}=\lambda I$
\end_inset

.
\end_layout

\begin_layout Itemize
Equivalent to a penalized likelihood: 
\begin_inset Formula 
\[
-2\cdot\log p(\beta\vert\sigma^{2},\mathbf{y},\mathbf{X})\propto RSS(\beta)+\lambda\beta'\beta
\]

\end_inset


\end_layout

\begin_layout Itemize
Posterior mean gives 
\series bold
ridge regression
\series default
 estimator
\begin_inset Formula 
\[
\tilde{\beta}=\left(\mathbf{X}'\mathbf{X}+\lambda I\right)^{-1}\mathbf{X}'\mathbf{y}
\]

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Shrinkage
\series default
 toward zero 
\begin_inset Formula 
\[
\text{As }\lambda\rightarrow\infty,\text{ }\tilde{\beta}\rightarrow0
\]

\end_inset


\end_layout

\begin_layout Itemize
When 
\begin_inset Formula $\mathbf{X}'\mathbf{X}=I$
\end_inset

 
\begin_inset Formula 
\[
\tilde{\beta}=\frac{1}{1+\lambda}\hat{\beta}_{OLS}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Bayesian spline with smoothness prior
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\align center
\begin_inset Graphics
	filename LidarPoly1Knots24.eps
	scale 55

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Smoothness prior for splines, cont.
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The famous 
\series bold
\color blue
Lasso
\series default
\color inherit
 variable selection method is equivalent to using the posterior mode estimate
 under the prior:
\begin_inset Formula 
\[
\beta_{i}|\sigma^{2}\overset{iid}{\sim}\mathrm{Laplace}\left(0,\frac{\sigma^{2}}{\lambda}\right)
\]

\end_inset

with density
\begin_inset Formula 
\[
p(\beta_{i})=\frac{\lambda}{2\sigma^{2}}\exp\left(-\frac{\lambda\left|\beta_{i}\right|}{\sigma^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
The Bayesian shrinkage prior is 
\series bold
interpretable
\series default
.
 
\series bold
Not ad hoc
\series default
.
\end_layout

\begin_layout Itemize
Laplace distribution have heavy tails.
\end_layout

\begin_layout Itemize
Laplace: many 
\begin_inset Formula $\beta_{i}$
\end_inset

 are close to zero, but some 
\begin_inset Formula $\beta_{i}$
\end_inset

 may be very large.
\end_layout

\begin_layout Itemize
Normal distribution have light tails.
 
\end_layout

\begin_layout Itemize
Normal prior: most 
\begin_inset Formula $\beta_{i}$
\end_inset

 are fairly equal in size, and no single 
\begin_inset Formula $\beta_{i}$
\end_inset

 can be very much larger than the other ones.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Estimating the shrinkage
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
How do we determine the degree of smoothness, 
\begin_inset Formula $\lambda$
\end_inset

? Cross-validation is one possible approach.
\end_layout

\begin_layout Itemize
Bayesian: 
\begin_inset Formula $\lambda$
\end_inset

 is unknown
\begin_inset Formula $\;\Rightarrow\;$
\end_inset

use a prior for 
\begin_inset Formula $\lambda$
\end_inset

.
\end_layout

\begin_layout Itemize
One possibility: 
\begin_inset Formula $\lambda\sim\mathsf{Gamma}\left(\frac{\eta_{0}}{2},\frac{\eta_{0}}{2\lambda_{0}}\right)$
\end_inset

.
 The user specifies 
\begin_inset Formula $\eta_{0}$
\end_inset

 and 
\begin_inset Formula $\lambda_{0}$
\end_inset

.
\end_layout

\begin_layout Itemize
Alternative approach: specify the prior on the 
\emph on
degrees of freedom
\emph default
.
\end_layout

\begin_layout Itemize
Hierarchical setup:
\begin_inset Formula 
\begin{align*}
\mathbf{y}|\beta,\mathbf{X} & \sim N(\mathbf{X}\beta,\sigma^{2}I_{n})\\
\beta|\sigma^{2},\lambda & \sim N\left(0,\sigma^{2}\lambda^{-1}I_{m}\right)\\
\sigma^{2} & \sim Inv-\chi^{2}(\nu_{0},\sigma_{0}^{2})\\
\lambda & \sim\mathsf{Gamma}\left(\frac{\eta_{0}}{2},\frac{\eta_{0}}{2\lambda_{0}}\right)
\end{align*}

\end_inset

so 
\begin_inset Formula $\Omega_{0}=\lambda I_{m}$
\end_inset

 in the previous notation.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
Regression with estimated shrinkage
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The joint posterior of 
\begin_inset Formula $\beta$
\end_inset

, 
\begin_inset Formula $\sigma^{2}$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

 is
\begin_inset Formula 
\begin{align*}
\beta|\sigma^{2},\lambda,\mathbf{y} & \sim N\left(\mu_{n},\Omega_{n}^{-1}\right)\\
\sigma^{2}|\lambda,\mathbf{y} & \sim Inv-\chi^{2}\left(\nu_{n},\sigma_{n}^{2}\right)\\
p(\lambda|\mathbf{y}) & \propto\sqrt{\frac{\left|\Omega_{0}\right|}{\left|\mathbf{X}^{T}\mathbf{X}+\Omega_{0}\right|}}\left(\frac{\nu_{n}\sigma_{n}^{2}}{2}\right)^{-\nu_{n}/2}\cdot p(\lambda)
\end{align*}

\end_inset

where 
\begin_inset Formula $\Omega_{0}=\lambda I_{m}$
\end_inset

, and 
\begin_inset Formula $p(\lambda)$
\end_inset

 is the prior for 
\begin_inset Formula $\lambda$
\end_inset

, and 
\begin_inset Formula 
\begin{align*}
\mu_{n} & =\left(\mathbf{X}^{T}\mathbf{X}+\Omega_{0}\right)^{-1}\mathbf{X}^{T}\mathbf{y}\\
\Omega_{n} & =\mathbf{X}^{T}\mathbf{X}+\Omega_{0}\\
\nu_{n} & =\nu_{0}+n\\
\nu_{n}\sigma_{n}^{2} & =\nu_{0}\sigma_{0}^{2}+\mathbf{y}^{T}\mathbf{y}-\mu_{n}^{T}\Omega_{n}\mu_{n}
\end{align*}

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator parbreak
\end_inset


\end_layout

\begin_layout Frame
\begin_inset Argument 4
status open

\begin_layout Plain Layout
More complexity
\end_layout

\end_inset


\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
The 
\series bold
\color blue
location of the knots
\series default
\color inherit
 can be treated as unknown, and estimated from the data.
 Joint posterior
\begin_inset Formula 
\[
p(\beta,\sigma^{2},\lambda,k_{1},...,k_{m}|\mathbf{y},\mathbf{X})
\]

\end_inset


\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
The marginal posterior for 
\begin_inset Formula $\lambda,k_{1},...,k_{m}$
\end_inset

 is a nightmare.
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Itemize
MCMC can be used to simulate from the joint posterior.
 Li and Villani (2013, SJS).
\end_layout

\begin_layout Itemize
The basic spline model can be extended with:
\begin_inset Separator latexpar
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
\color blue
Heteroscedastic errors
\series default
\color inherit
 (also modelled with a spline)
\end_layout

\begin_layout Itemize

\series bold
\color blue
Non-normal errors
\series default
\color inherit
 (student-t or mixture distributions)
\end_layout

\begin_layout Itemize

\series bold
\color blue
Autocorrelated/dependent errors
\series default
\color inherit
 (AR process for the error term)
\end_layout

\end_deeper
\begin_layout Itemize
MCMC can again be used to simulate from the joint posterior.
\end_layout

\end_deeper
\end_body
\end_document
